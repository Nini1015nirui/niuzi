#!/usr/bin/env python3
"""
Custom Dataset Preparation and Validation Tool for Spatial-Mamba Segmentation
è‡ªå®šä¹‰æ•°æ®é›†å‡†å¤‡å’ŒéªŒè¯å·¥å…·

åŠŸèƒ½ï¼š
1. éªŒè¯æ•°æ®é›†æ ¼å¼
2. ç”Ÿæˆç±»åˆ«ç»Ÿè®¡ä¿¡æ¯
3. æ£€æŸ¥å›¾åƒå’Œæ ‡æ³¨å¯¹åº”å…³ç³»
4. å¯è§†åŒ–æ•°æ®æ ·æœ¬
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
from collections import Counter
import argparse


class CustomDatasetValidator:
    """è‡ªå®šä¹‰æ•°æ®é›†éªŒè¯å™¨"""
    
    def __init__(self, dataset_root):
        self.dataset_root = Path(dataset_root)
        self.stats = {
            'train_images': 0,
            'val_images': 0,
            'train_annotations': 0,
            'val_annotations': 0,
            'classes': set(),
            'errors': []
        }
    
    def validate_structure(self):
        """éªŒè¯æ•°æ®é›†æ–‡ä»¶å¤¹ç»“æ„"""
        print("ğŸ” éªŒè¯æ•°æ®é›†ç»“æ„...")
        
        required_dirs = [
            'images/training',
            'images/validation', 
            'annotations/training',
            'annotations/validation'
        ]
        
        for dir_path in required_dirs:
            full_path = self.dataset_root / dir_path
            if not full_path.exists():
                self.stats['errors'].append(f"ç¼ºå°‘ç›®å½•: {dir_path}")
                print(f"âŒ ç¼ºå°‘ç›®å½•: {full_path}")
            else:
                print(f"âœ… ç›®å½•å­˜åœ¨: {dir_path}")
        
        return len(self.stats['errors']) == 0
    
    def validate_files(self):
        """éªŒè¯æ–‡ä»¶å¯¹åº”å…³ç³»å’Œæ ¼å¼"""
        print("\nğŸ” éªŒè¯æ–‡ä»¶å¯¹åº”å…³ç³»...")
        
        # æ£€æŸ¥è®­ç»ƒé›†
        self._validate_split('training')
        # æ£€æŸ¥éªŒè¯é›†
        self._validate_split('validation')
        
        return len(self.stats['errors']) == 0
    
    def _validate_split(self, split):
        """éªŒè¯å•ä¸ªæ•°æ®åˆ†å‰²"""
        img_dir = self.dataset_root / 'images' / split
        ann_dir = self.dataset_root / 'annotations' / split
        
        # è·å–å›¾åƒæ–‡ä»¶
        img_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            img_files.extend(img_dir.glob(ext))
        
        # è·å–æ ‡æ³¨æ–‡ä»¶
        ann_files = list(ann_dir.glob('*.png'))
        
        self.stats[f'{split}_images'] = len(img_files)
        self.stats[f'{split}_annotations'] = len(ann_files)
        
        print(f"  {split}: {len(img_files)} å›¾åƒ, {len(ann_files)} æ ‡æ³¨")
        
        # æ£€æŸ¥å¯¹åº”å…³ç³»
        for img_file in img_files:
            # æ„é€ å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶å
            ann_file = ann_dir / (img_file.stem + '.png')
            
            if not ann_file.exists():
                error = f"{split}: å›¾åƒ {img_file.name} ç¼ºå°‘å¯¹åº”æ ‡æ³¨"
                self.stats['errors'].append(error)
                print(f"âŒ {error}")
                continue
            
            # éªŒè¯æ ‡æ³¨æ–‡ä»¶
            try:
                ann = cv2.imread(str(ann_file), cv2.IMREAD_GRAYSCALE)
                if ann is None:
                    error = f"{split}: æ— æ³•è¯»å–æ ‡æ³¨æ–‡ä»¶ {ann_file.name}"
                    self.stats['errors'].append(error)
                    print(f"âŒ {error}")
                    continue
                
                # ç»Ÿè®¡ç±»åˆ«
                unique_labels = np.unique(ann)
                self.stats['classes'].update(unique_labels.tolist())
                
            except Exception as e:
                error = f"{split}: æ ‡æ³¨æ–‡ä»¶ {ann_file.name} é”™è¯¯: {str(e)}"
                self.stats['errors'].append(error)
                print(f"âŒ {error}")
    
    def analyze_classes(self):
        """åˆ†æç±»åˆ«åˆ†å¸ƒ"""
        print("\nğŸ“Š åˆ†æç±»åˆ«åˆ†å¸ƒ...")
        
        class_counts = Counter()
        
        for split in ['training', 'validation']:
            ann_dir = self.dataset_root / 'annotations' / split
            ann_files = list(ann_dir.glob('*.png'))
            
            for ann_file in ann_files:
                try:
                    ann = cv2.imread(str(ann_file), cv2.IMREAD_GRAYSCALE)
                    if ann is not None:
                        unique, counts = np.unique(ann, return_counts=True)
                        for cls, count in zip(unique, counts):
                            class_counts[cls] += count
                except:
                    continue
        
        print(f"å‘ç° {len(class_counts)} ä¸ªç±»åˆ«:")
        for cls in sorted(class_counts.keys()):
            print(f"  ç±»åˆ« {cls}: {class_counts[cls]:,} åƒç´ ")
        
        # ä¿å­˜ç±»åˆ«ä¿¡æ¯
        class_info = {
            'num_classes': len(class_counts),
            'class_names': [f'class_{i}' for i in sorted(class_counts.keys())],
            'class_pixel_counts': dict(class_counts)
        }
        
        info_file = self.dataset_root / 'dataset_info.json'
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(class_info, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ç±»åˆ«ä¿¡æ¯å·²ä¿å­˜åˆ°: {info_file}")
        
        return class_info
    
    def visualize_samples(self, num_samples=3):
        """å¯è§†åŒ–æ•°æ®æ ·æœ¬"""
        print(f"\nğŸ–¼ï¸ å¯è§†åŒ– {num_samples} ä¸ªæ ·æœ¬...")
        
        # åˆ›å»ºå¯è§†åŒ–ç›®å½•
        vis_dir = self.dataset_root / 'visualization'
        vis_dir.mkdir(exist_ok=True)
        
        # ä»è®­ç»ƒé›†é€‰æ‹©æ ·æœ¬
        img_dir = self.dataset_root / 'images' / 'training'
        ann_dir = self.dataset_root / 'annotations' / 'training'
        
        img_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))
        
        for i, img_file in enumerate(img_files[:num_samples]):
            ann_file = ann_dir / (img_file.stem + '.png')
            
            if not ann_file.exists():
                continue
            
            # è¯»å–å›¾åƒå’Œæ ‡æ³¨
            img = cv2.imread(str(img_file))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            ann = cv2.imread(str(ann_file), cv2.IMREAD_GRAYSCALE)
            
            # åˆ›å»ºå¯è§†åŒ–
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            
            # åŸå›¾
            axes[0].imshow(img)
            axes[0].set_title('Original Image')
            axes[0].axis('off')
            
            # æ ‡æ³¨å›¾
            axes[1].imshow(ann, cmap='tab20')
            axes[1].set_title('Annotation')
            axes[1].axis('off')
            
            # å åŠ å›¾
            overlay = img.copy()
            colored_ann = plt.cm.tab20(ann / ann.max())[:, :, :3]
            overlay = (overlay * 0.6 + colored_ann * 255 * 0.4).astype(np.uint8)
            axes[2].imshow(overlay)
            axes[2].set_title('Overlay')
            axes[2].axis('off')
            
            plt.tight_layout()
            vis_file = vis_dir / f'sample_{i+1}.png'
            plt.savefig(vis_file, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"  å·²ä¿å­˜å¯è§†åŒ–: {vis_file}")
    
    def generate_config_template(self, num_classes):
        """ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿"""
        print(f"\nğŸ“ ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿...")
        
        config_template = f'''# è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®æ–‡ä»¶æ¨¡æ¿
# è¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å‚æ•°

_base_ = [
    '../_base_/models/upernet_r50.py',
    '../_base_/datasets/custom_dataset.py',
    '../_base_/default_runtime.py',
    '../_base_/schedules/schedule_160k.py'
]

# æ•°æ®é›†è·¯å¾„ï¼ˆç›¸å¯¹äºsegmentationç›®å½•ï¼‰
data_root = '{self.dataset_root.relative_to(Path.cwd())}'

# æ¨¡å‹é…ç½®
model = dict(
    backbone=dict(
        type='MM_SpatialMamba',
        out_indices=(0, 1, 2, 3),
        pretrained="",
        dims=64,  # tiny: 64, small: 96, base: 128
        d_state=1,
        depths=(2, 4, 8, 4),
        drop_path_rate=0.2,
    ),
    decode_head=dict(
        in_channels=[64, 128, 256, 512],
        num_classes={num_classes},  # åŒ…æ‹¬èƒŒæ™¯ç±»
    ),
    auxiliary_head=dict(
        in_channels=256,
        num_classes={num_classes},
    )
)

# æ•°æ®åŠ è½½é…ç½®
train_dataloader = dict(
    batch_size=2,  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
    dataset=dict(data_root=data_root))

val_dataloader = dict(
    batch_size=1,
    dataset=dict(data_root=data_root))

test_dataloader = dict(
    batch_size=1,
    dataset=dict(data_root=data_root))

# è®­ç»ƒé…ç½®
train_cfg = dict(
    max_iters={max(20000, self.stats['train_images'] * 100)},  # æ ¹æ®æ•°æ®é‡è°ƒæ•´
    val_interval=2000
)

# å·¥ä½œç›®å½•
work_dir = './work_dirs/{self.dataset_root.name}_training'
'''
        
        config_file = self.dataset_root / 'suggested_config.py'
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(config_template)
        
        print(f"ğŸ“„ é…ç½®æ–‡ä»¶æ¨¡æ¿å·²ä¿å­˜åˆ°: {config_file}")
    
    def run_validation(self):
        """è¿è¡Œå®Œæ•´éªŒè¯æµç¨‹"""
        print("ğŸš€ å¼€å§‹éªŒè¯è‡ªå®šä¹‰æ•°æ®é›†...")
        print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {self.dataset_root}")
        
        # 1. éªŒè¯ç»“æ„
        if not self.validate_structure():
            print("\nâŒ æ•°æ®é›†ç»“æ„éªŒè¯å¤±è´¥!")
            return False
        
        # 2. éªŒè¯æ–‡ä»¶
        if not self.validate_files():
            print("\nâŒ æ–‡ä»¶éªŒè¯å¤±è´¥!")
            return False
        
        # 3. åˆ†æç±»åˆ«
        class_info = self.analyze_classes()
        
        # 4. å¯è§†åŒ–æ ·æœ¬
        self.visualize_samples()
        
        # 5. ç”Ÿæˆé…ç½®æ¨¡æ¿
        self.generate_config_template(class_info['num_classes'])
        
        # 6. è¾“å‡ºæ€»ç»“
        print("\nğŸ“‹ éªŒè¯æ€»ç»“:")
        print(f"  âœ… è®­ç»ƒå›¾åƒ: {self.stats['train_images']}")
        print(f"  âœ… éªŒè¯å›¾åƒ: {self.stats['val_images']}")
        print(f"  âœ… ç±»åˆ«æ•°é‡: {class_info['num_classes']}")
        print(f"  âœ… é”™è¯¯æ•°é‡: {len(self.stats['errors'])}")
        
        if len(self.stats['errors']) == 0:
            print("\nğŸ‰ æ•°æ®é›†éªŒè¯é€šè¿‡! å¯ä»¥å¼€å§‹è®­ç»ƒäº†!")
            print("\nğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:")
            print(f"1. å¤åˆ¶ç”Ÿæˆçš„é…ç½®æ–‡ä»¶åˆ° configs/spatialmamba/")
            print(f"2. æ ¹æ®éœ€è¦è°ƒæ•´é…ç½®å‚æ•°")
            print(f"3. å¼€å§‹è®­ç»ƒ: python tools/train.py configs/spatialmamba/your_config.py")
        else:
            print("\nâš ï¸ å‘ç°ä»¥ä¸‹é”™è¯¯ï¼Œè¯·ä¿®å¤åé‡æ–°éªŒè¯:")
            for error in self.stats['errors']:
                print(f"   - {error}")
        
        return len(self.stats['errors']) == 0


def main():
    parser = argparse.ArgumentParser(description='éªŒè¯å’Œå‡†å¤‡è‡ªå®šä¹‰åˆ†å‰²æ•°æ®é›†')
    parser.add_argument('dataset_path', help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--samples', type=int, default=3, help='å¯è§†åŒ–æ ·æœ¬æ•°é‡')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.dataset_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {args.dataset_path}")
        return
    
    validator = CustomDatasetValidator(args.dataset_path)
    validator.run_validation()


if __name__ == '__main__':
    main()